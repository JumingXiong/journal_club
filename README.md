# Journal-Club
Time: Friday morning 10:00 - 10:30 AM, FGH 313

- [Journal-Club](#Journal-Club)
	- [Paper-Reading-Group](#paper-reading-group)
  
## Paper-Reading-Group

Agenda

|Date|Speaker|Paper|Remark|
|---|:---:|---|---|
|2024.10.4|Yuechen Yang Guo    <br>  （Generative model）  |[《Enhancing Representation in Radiography-Reports Foundation Model: A Granular Alignment Algorithm Using Masked Contrastive Learning》   (CVPR2023)](https://arxiv.org/abs/2309.05904)
|2024.10.4|Yuechen Yang    <br>  （Generative model）  |[《Enhancing Representation in Radiography-Reports Foundation Model: A Granular Alignment Algorithm Using Masked Contrastive Learning》   (CVPR2023)](https://arxiv.org/abs/2309.05904)
|2024.10.4|Yuechen Yang    <br>  （Generative model）  |[《Enhancing Representation in Radiography-Reports Foundation Model: A Granular Alignment Algorithm Using Masked Contrastive Learning》   (Nature Communication)](https://arxiv.org/abs/2309.05904)
|2024.09.27|Junlin Guo    <br>  （Vision-language model）  |[《Enhancing Representation in Radiography-Reports Foundation Model: A Granular Alignment Algorithm Using Masked Contrastive Learning》   (Nature Communication)](https://arxiv.org/abs/2309.05904)
|2024.09.27|Junlin Guo    <br>  （Vision-language model）  |[《Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding》   (Arxiv)](https://www.arxiv.org/abs/2405.19567)
|2024.09.27|Junlin Guo    <br>  （Segmentation）  |[《Unleashing the Potential of SAM for Medical Adaptation via Hierarchical Decoding》   (CVPR2024)](https://arxiv.org/abs/2403.18271)
|2024.09.20|Juming Xiong    <br>  （Image Registration）  |[《RegWSI: Whole slide image registration using combined deep feature-and intensity-based methods: Winner of the ACROBAT 2023 challenge》   (Computer Methods and Programs in Biomedicine)](https://arxiv.org/pdf/2404.13108v2)
|2024.09.20|Juming Xiong    <br>  （Image Registration）|[《Unsupervised Non-rigid Histological Image Registration Guided by Keypoint Correspondences Based on Learnable Deep Features with Iterative Training》  (TMI)](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10643202)
|2024.09.20|Juming Xiong    <br>  （Image Segmentation）|[《Feature-prompting GBMSeg: One-Shot Reference Guided Training-Free Prompt Engineering for Glomerular Basement Membrane Segmentation》  (MICCAI)](https://arxiv.org/pdf/2406.16271)
|2024.09.13|Cathy Cui    <br>  （Vision-language model）  |[《Segment Everything Everywhere All at Once》   (NeurIPS 2023)](https://openreview.net/pdf?id=UHBrWeFWlL)
|2024.09.13|Cathy Cui    <br>  （Vision-language model）|[《Semantic-SAM: Segment and Recognize Anything at Any Granularity》  (ArXiv)](https://arxiv.org/abs/2307.04767)
|2024.09.13|Cathy Cui    <br>  （Vision-language model）|[《BiomedParse: a biomedical foundation model for image parsing of everything everywhere all at once》  (ArXiv)](https://arxiv.org/abs/2405.12971)
|2024. 9.6 | Ruining Deng  <br> （GAN-based application）  |[《CP2Image: Generating high-quality single-cell images using CellProfiler representations》 （MIDL2023）](https://proceedings.mlr.press/v227/ji24a.html)
|2024. 9.6 | Ruining Deng  <br> （Image Registration）  |[《Unsupervised Histological Image Registration Using Structural Feature Guided Convolutional Neural Network》 （IEEE TMI)](https://ieeexplore.ieee.org/document/9745959)
|2024. 9.6 | Ruining Deng  <br> （Vision-Language model）  |[《ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for Whole Slide Image Classification》 （CVPR2024)](https://openaccess.thecvf.com/content/CVPR2024/papers/Shi_ViLa-MIL_Dual-scale_Vision-Language_Multiple_Instance_Learning_for_Whole_Slide_Image_CVPR_2024_paper.pdf)
|2024.08.30|Tianyuan Yao    <br>  （Vision language Model）  |[《BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models》 (ArXiv）](https://arxiv.org/pdf/2301.12597.pdf)
|2024.08.30|Tianyuan Yao    <br>  （Vision language Model）  |[《BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation》 (ArXiv）](https://arxiv.org/pdf/2201.12086.pdf)
|2024.08.30|Tianyuan Yao    <br>  （Vision language Model）  |[《Align before Fuse: Vision and Language Representation Learning with Momentum Distillation》 (ArXiv）](https://arxiv.org/pdf/2107.07651.pdf)
|2024.08.23 | Marilyn Lionts  <br> （digital pathology virtual staining）  |[《Virtual histological staining of unlabeled autopsy tissue》 （Nature Communications 2024）](https://www.nature.com/articles/s41467-024-46077-2)
|2024.08.23 | Marilyn Lionts  <br> （LLM）  |[《META-REWARDING LANGUAGE MODELS: Self-Improving Alignment with LLM-as-a-Meta-Judge》 （ArXiv 2024）](https://arxiv.org/pdf/2407.19594)
|2024.08.23 | Marilyn Lionts  <br> （AI Safety）  |[《Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?》 （ArXiv 2024）](https://arxiv.org/pdf/2407.21792)
|2024.07.26 | Junchao Zhu  <br> （pseudo label + semi-supervised learning）  |[《Co-training with High-Confidence Pseudo Labels for Semi-supervised Medical Image Segmentation》 （IJCAI 2023）](https://dl.acm.org/doi/10.24963/ijcai.2023/467)
|2024.07.26 | Junchao Zhu  <br> （pseudo label + semi-supervised learning）  |[《Conflict-Based Cross-View Consistency for Semi-Supervised Semantic Segmentation》 （CVPR2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Conflict-Based_Cross-View_Consistency_for_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf)
|2024.07.26 | Junchao Zhug  <br> （pseudo label + semi-supervised learning）  |[《Mutual learning with reliable pseudo label for semi-supervised medical image segmentation》 （MEDIA）](https://www.sciencedirect.com/science/article/pii/S1361841524000367)
|2024.07.19 | Yuechen Yang  <br> （image analysis toolbox）  |[《TIAToolbox as an end-to-end library for advanced tissue image analytics》 （ communications medicine 2022）](https://www.nature.com/articles/s43856-022-00186-5)
|2024.07.19 | Yuechen Yang  <br> （feature extraction + ML）  |[《Classification of Citrus Type Based on Leaf Image Using Shape Extraction and GLCM with the Decision Tree Method》 （IEEE 2021）](https://ieeexplore.ieee.org/abstract/document/9573252)
|2024.07.19 | Yuechen Yang  <br> （feature extraction + ML）  |[《Sliding Window Based Support Vector Machine System for Classification of Breast Cancer Using Histopathological Microscopic Images》 （IETE 2019）](https://www.tandfonline.com/doi/abs/10.1080/03772063.2019.1583610)
|2024.07.05 | Ruining Deng  <br> （Multi-modal Learning）  |[《Transcriptomics-guided Slide Representation Learning in Computational Pathology》 （CVPR2024）](https://openaccess.thecvf.com/content/CVPR2024/papers/Jaume_Transcriptomics-guided_Slide_Representation_Learning_in_Computational_Pathology_CVPR_2024_paper.pdf)
|2024.07.05 | Ruining Deng  <br> （Multi-rater Learning）  |[《Stochastic In-Context Learning for Medical Image Segmentation》 （CVPR2024）](https://openaccess.thecvf.com/content/CVPR2024/papers/Rakic_Tyche_Stochastic_In-Context_Learning_for_Medical_Image_Segmentation_CVPR_2024_paper.pdf)
|2024.07.05 | Ruining Deng  <br> （Continual Learning）  |[《Continual Self-supervised Learning: Towards Universal Multi-modal Medical Data Representation Learning》 （CVPR2024)](https://openaccess.thecvf.com/content/CVPR2024/papers/Ye_Continual_Self-supervised_Learning_Towards_Universal_Multi-modal_Medical_Data_Representation_Learning_CVPR_2024_paper.pdf)
|2024.06.21|Juming Xiong    <br>  （Image Stitching）  |[《Unsupervised Deep Image Stitching: Reconstructing Stitched Features to Images》(IEEE TRANSACTIONS ON IMAGE PROCESSING)](https://arxiv.org/pdf/2106.12859)
|2024.06.21|Juming Xiong    <br>  （Image Stitching）|[《Parallax-Tolerant Unsupervised Deep Image Stitching》](https://arxiv.org/pdf/2302.08207))
|2024.06.21|Juming Xiong    <br>  （Image Stitching）|[《Implicit Neural Image Stitching With Enhanced and Blended Feature Reconstruction》](https://arxiv.org/pdf/2309.01409)
|2024.06.14|Tianyuan Yao    <br>  （Time series foundation model）  |[《Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting》](https://arxiv.org/pdf/1912.09363.pdf)
|2024.06.14|Tianyuan Yao    <br>  （Time series foundation model）  |[《Spatial-Temporal Transformer Networks for Traffic Flow Forecasting》](https://arxiv.org/pdf/2001.02908.pdf)
|2024.06.14|Tianyuan Yao    <br>  （Time series foundation model）  |[《Foundation Models for Time Series Analysis: A Tutorial and Survey》](https://arxiv.org/pdf/2403.14735.pdf)
|2024.05.24|Marilyn Lionts    <br>  （Transformers）  |[《Improving Transformers Using Faithful Positional Encoding》 (ArXiv）](https://arxiv.org/pdf/2405.09061v1)
|2024.05.24|Marilyn Lionts    <br>  （Transformers）  |[《Zero-Shot Tokenizer Transfer》 (ArXiv）](https://arxiv.org/pdf/2405.07883#:~:text=While%20past%20work%20investigated%20n-shot%20tokenizer%20transfer%2C%20we,LMs%20from%20the%20tokenizer%20they%20were%20trained%20with.)
|2024.05.24|Marilyn Lionts    <br>  （Language Models）  |[《Observational Scaling Laws and the Predictability of Language Model Performance》 (ArXiv）](https://arxiv.org/pdf/2405.10938)
|2024.05.03|Junlin Guo    <br>  （RLHF + Large Language Model）  |[《Aligning Large Multimodal Models with Factually Augmented RLHF》 (ArXiv）](https://arxiv.org/abs/2309.14525)
|2024.05.03|Junlin Guo    <br>  （RLHF + Diffusion Model）  |[《Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model》 (CVPR2024）](https://arxiv.org/abs/2311.13231)
|2024.04.26|Tianyuan Yao    <br>  （Large language Model）  |[《Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking》 (ArXiv）](https://arxiv.org/pdf/2403.09629.pdf)
|2024.04.26|Tianyuan Yao    <br>  （Large language Model）  |[《Mixture-of-Depths: Dynamically allocating compute in transformer-based language models》 (ArXiv）](https://arxiv.org/pdf/2404.02258.pdf)
|2024.04.26|Tianyuan Yao    <br>  （Large language Model）  |[《Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention》 (ArXiv）](https://arxiv.org/pdf/2404.07143.pdf)
|2024.04.19|Marilyn Lionts  <br> （Spatial Awareness LLMs）  |[《BLINK: Multimodal Large Language Models Can See but Not Perceive》 (ArXiv）](https://arxiv.org/pdf/2404.12390.pdf)
|2024.04.19|Marilyn Lionts  <br> （Spatial Awareness LLMs）  |[《Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models》 （ArXiv）](https://arxiv.org/pdf/2404.03622.pdf)
|2024.04.19|Marilyn Lionts  <br> （Adversarial LLMs）  |[《Manipulating Large Language Models to Increase Product Visibility》 （ArXiv)](https://arxiv.org/pdf/2404.07981.pdf)
|2024.04.12|Quan Liu  <br> （Small Language Model）  |[《Textbooks Are All You Need》 (ArXiv）](https://arxiv.org/abs/2306.11644)
|2024.04.12|Quan Liu  <br> （Small Language Model）  |[《Small Models are Valuable Plug-ins for Large Language Models》 （ArXiv）](https://arxiv.org/abs/2305.08848)
|2024.04.12|Quan Liu  <br> （Small Language Model）  |[《MobileVLM V2: Faster and Stronger Baseline for Vision Language Model》 （ArXiv)](https://arxiv.org/pdf/2402.03766.pdf)
|2024.04.05|Ruining Deng  <br> （Class-incremental Learning）  |[《PLOP: Learning without Forgetting for Continual Semantic Segmentation》 （CVPR2021）](https://openaccess.thecvf.com/content/CVPR2021/papers/Douillard_PLOP_Learning_Without_Forgetting_for_Continual_Semantic_Segmentation_CVPR_2021_paper.pdf)
|2024.04.05|Ruining Deng  <br> （Class-incremental Learning）  |[《Class Similarity Weighted Knowledge Distillation for Continual Semantic Segmentation》 （CVPR2022）](https://openaccess.thecvf.com/content/CVPR2022/papers/Phan_Class_Similarity_Weighted_Knowledge_Distillation_for_Continual_Semantic_Segmentation_CVPR_2022_paper.pdf)
|2024.04.05|Ruining Deng  <br> （Class-incremental Learning）  |[《CoMFormer: Continual Learning in Semantic and Panoptic Segmentation》 （CVPR2023) ](https://openaccess.thecvf.com/content/CVPR2023/papers/Cermelli_CoMFormer_Continual_Learning_in_Semantic_and_Panoptic_Segmentation_CVPR_2023_paper.pdf)
|2024.03.29|Cathy Cui  <br>  （Efficient Model）  |[《PromptKD: Unsupervised Prompt Distillation for Vision-Language Models》](https://arxiv.org/abs/2403.02781)
|2024.03.29|Cathy Cui  <br>  （Efficient Model）  |[《Omni-SMoLA: Boosting Generalist Multimodal Models with Soft Mixture of Low-rank Experts》](https://arxiv.org/pdf/2312.00968.pdf)
|2024.03.29|Cathy Cui  <br>  （Efficient Model）  |[《EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything》](https://arxiv.org/pdf/2312.00863.pdf)
|2024.03.22|Juming Xiong    <br>  （Generative Model）  |[《Endora: Video Generation Models as Endoscopy Simulators》](https://arxiv.org/pdf/2403.11050.pdf)
|2024.03.22|Juming Xiong    <br>  （Image Segmentation）|[《OMG-Seg: Is One Model Good Enough For All Segmentation》(CVPR 2024)](https://arxiv.org/pdf/2401.10229.pdf)
|2024.03.22|Juming Xiong    <br>  （Image registration）|[《Modality-Agnostic Structural Image Representation Learning for Deformable Multi-Modality Medical Image Registration》(CVPR 2024)](https://arxiv.org/pdf/2402.18933.pdf)
|2024.03.15|Yucheng Tang    <br>  （Autoregressive Models）  |[《Taming Transformers for High-Resolution Image Synthesis》(CVPR 2021)](https://arxiv.org/pdf/2012.09841.pdf)
|2024.03.15|Yucheng Tang    <br>  （Autoregressive Models）  |[《Sequential Modeling Enables Scalable Learning for Large Vision Models》](https://arxiv.org/pdf/2312.00785.pdf)
|2024.03.15|Yucheng Tang    <br>  （Autoregressive Models）  |[《VILA: On Pre-training for Visual Language Models》(CVPR 2024)](https://arxiv.org/pdf/2312.07533.pdf)
|2024.03.01|Junlin Guo    <br>  （Visual Language model + Dataset denoising）  |[《Filtering, distillation, and hard negatives for vision-language pre-training》(CVPR 2023)](https://arxiv.org/pdf/2301.02280.pdf)
|2024.03.01|Junlin Guo    <br>  （Foundation model + Weakly supervised learning）  |[《Foundation Model Drives Weakly Incremental Learning for Semantic Segmentation》(CVPR 2023)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Foundation_Model_Drives_Weakly_Incremental_Learning_for_Semantic_Segmentation_CVPR_2023_paper.pdf)
|2024.03.01|Junlin Guo    <br>  （Self-supervised Pre-training）  |[《Geometric Visual Similarity Learning in 3D Medical Image Self-supervised Pre-training》(CVPR 2023)](https://openaccess.thecvf.com/content/CVPR2023/html/He_Geometric_Visual_Similarity_Learning_in_3D_Medical_Image_Self-Supervised_Pre-Training_CVPR_2023_paper.html)
|2024.02.23|Tianyuan Yao    <br>  （Vision 'language' Model）  |[《Images Speak in Images: A Generalist Painter for In-Context Visual Learning》](https://arxiv.org/pdf/2212.02499.pdf)
|2024.02.23|Tianyuan Yao    <br>  （Machine unlearning）  |[《UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models》](https://arxiv.org/pdf/2402.11846.pdf)
|2024.02.16|Marilyn Lionts     <br>  （Unlearnable Datasets）  |[《UNLEARNABLE EXAMPLES: MAKING PERSONAL DATA UNEXPLOITABLE》(ICLR2021）](https://arxiv.org/pdf/2101.04898.pdf)
|2024.02.16|Marilyn Lionts     <br>  （Unlearnable Datasets）  |[《CUDA: Convolution-based Unlearnable Datasets》(CVPR 2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Sadasivan_CUDA_Convolution-Based_Unlearnable_Datasets_CVPR_2023_paper.pdf)
|2024.02.16|Marilyn Lionts     <br>  （Unlearnable Datasets）  |[《Unlearnable Clusters: Towards Label-agnostic Unlearnable Examples》(CVPR 2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Unlearnable_Clusters_Towards_Label-Agnostic_Unlearnable_Examples_CVPR_2023_paper.pdf)
|2024.02.09|Quan Liu     <br>  （Multi-modal Large Language Models (MLLM）  |[《Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization》（ArXiv）](https://arxiv.org/pdf/2309.04669.pdf)
|2024.02.09|Quan Liu     <br>  （MLLM）  |[《GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest》(ArXiv）](https://jshilong.github.io/images/gpt4roi.pdf)
|2024.02.09|Quan Liu     <br>  （MLLM）  |[《DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding》(ArXiv）](https://arxiv.org/pdf/2311.11810.pdf)
|2024.02.02 | Ruining Deng  <br> （Hierarchical Semantic Segmentation）  |[《Deep Hierarchical Semantic Segmentation》 （CVPR2022)](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Deep_Hierarchical_Semantic_Segmentation_CVPR_2022_paper.pdf)
|2024.02.02 | Ruining Deng  <br> （Hierarchical Semantic Segmentation）  |[《Unsupervised Hierarchical Semantic Segmentation with Multiview Cosegmentation and Clustering Transformers 》 （CVPR2022）](https://openaccess.thecvf.com/content/CVPR2022/papers/Ke_Unsupervised_Hierarchical_Semantic_Segmentation_With_Multiview_Cosegmentation_and_Clustering_Transformers_CVPR_2022_paper.pdf)
|2024.02.02 | Ruining Deng  <br> （Universal segmentation）  |[《UniverSeg: Universal Medical Imaging Segmentation》 （ICCV2023](https://arxiv.org/pdf/2304.06131.pdf)
|2024.01.26|Can(Cathy) Cui     <br>  （Vision Language Model）  |[《LISA: Reasoning Segmentation via Large Language Model》 （ArXiv）](https://arxiv.org/pdf/2308.00692.pdf)
|2024.01.26|Can(Cathy) Cui     <br>  （Vision Language Model）  |[《Making Large Multimodal Models Understand Arbitrary Visual Prompts 》(ArXiv）](https://arxiv.org/pdf/2312.00784.pdf)
|2024.01.26|Can(Cathy) Cui     <br>  （Network Structure）  |[《U-Mamba Enhancing Long-range Dependency for Biomedical Image Segmentation》(ArXiv）](https://wanglab.ai/u-mamba.html)
|2024.01.12 | Yucheng Tang  <br> （Efficient ViT）  |[《EfficientViT: Multi-Scale Linear Attention for High-Resolution Dense Prediction》 （ICCV 2023）](https://arxiv.org/pdf/2205.14756.pdf)
|2024.01.12 | Yucheng Tang  <br> Sparse ViT）  |[《SparseViT: Revisiting Activation Sparsity for Efficient High-Resolution Vision Transformer》 (CVPR) 2023）](https://arxiv.org/pdf/2303.17605.pdf)
|2024.01.12 | Yucheng Tang  <br> （Open-Vocabulary SAM）  |[《Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively》](https://arxiv.org/pdf/2401.02955.pdf)
|2023.11.17 | Dr. Huo  <br> （Spatial Transcriptomics）  |[《Visualization and Analysis of Gene Expression in Tissue Sections by Spatial Transcriptomics》 （Science 2016）](https://www.science.org/doi/10.1126/science.aaf2403?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%20%200pubmed)
|2023.11.17 | Dr. Huo  <br> （Spatial Transcriptomics）  |[《Spatially Resolved Transcriptomes—Next Generation Tools for Tissue Exploration》 （BioEssay 2020）](https://onlinelibrary.wiley.com/doi/full/10.1002/bies.201900221)
|2023.11.17 | Dr. Huo  <br> （Spatial Transcriptomics）  |[《Alignment and Integration of Spatial Transcriptomics Data》 （Nature Method 2022）](https://www.nature.com/articles/s41592-022-01459-6)
|2023.11.10 | Quan Liu  <br> （Vision Language Foundation Model）  |[《Multimodal Few-Shot Learning with Frozen Language Models》 （NeruIPS 2021）](https://arxiv.org/pdf/2106.13884.pdf)
|2023.11.10 | Quan Liu  <br> （Vision Language Foundation Model）  |[《Frozen Transformers in Language Models Are Effective Visual Encoder Layers》 （arxiv）](https://arxiv.org/pdf/2310.12973.pdf)
|2023.11.10 | Quan Liu  <br> （Tranformer CNN backbone comparison）  |[《ConvNets Match Vision Transformers at Scale》 （DeepMind）](https://arxiv.org/pdf/2310.16764.pdf)
|2023.11.03 | Junlin Guo  <br> （Long-Tailed Learning + Knowledge Distillation）  |[《Long-Tailed Visual Recognition via Self-Heterogeneous Integration with Knowledge Excavation》 （CVPR 2023）](https://arxiv.org/pdf/2304.01279.pdf)
|2023.11.03 | Junlin Guo  <br> （Universal instance cell segmentation）  |[《Cellpose: a generalist algorithm for cellular segmentation》 （Nature. 2021）](https://www.nature.com/articles/s41592-020-01018-x)
|2023.11.03 | Junlin Guo  <br> （Universal instance cell segmentation + Harmony）  |[《MEDIAR: Harmony of Data-Centric and Model-Centric for Multi-Modality Microscopy》 （NeurIPS 2022）](http://arxiv.org/abs/2212.03465)
|2023.10.27 | Marilyn Lionts  <br> （Variational Autoencoders and Active Learning）  |[《An Active Learning Method Based on Variational Autoencoder and DBSCAN Clustering》 （2021）](https://downloads.hindawi.com/journals/cin/2021/9952596.pdf)
|2023.10.27 | Marilyn Lionts  <br> （Variational Autoencoders and Active Learning）  |[《The Power of Ensembles for Active Learning in Image Classification》 （CVPR 2018）](https://openaccess.thecvf.com/content_cvpr_2018/papers/Beluch_The_Power_of_CVPR_2018_paper.pdf)
|2023.10.27 | Marilyn Lionts  <br> （Variational Autoencoders and Active Learning）  |[《Variational Adversarial Active Learning》 （ICCV 2019）](https://openaccess.thecvf.com/content_ICCV_2019/papers/Sinha_Variational_Adversarial_Active_Learning_ICCV_2019_paper.pdf)
|2023.10.20 | Can(Cathy) Cui  <br> （Anomaly Detection and Localization）  |[《Anomaly Detection via Reverse Distillation from One-Class Embedding》 （CVPR2022）](https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_Anomaly_Detection_via_Reverse_Distillation_From_One-Class_Embedding_CVPR_2022_paper.pdf)
|2023.10.20 | Can(Cathy) Cui  <br> （Anomaly Detection and Localization）  |[《Revisiting Reverse Distillation for Anomaly Detection》 （CVPR2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Tien_Revisiting_Reverse_Distillation_for_Anomaly_Detection_CVPR_2023_paper.pdf)
|2023.10.20 | Can(Cathy) Cui  <br> （Anomaly Detection and Localization）  |[《ReContrast: Domain-Specific Anomaly Detection via Contrastive Reconstruction》 （NeurIPS）](https://arxiv.org/abs/2306.02602)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《Flamingo: a Visual Language Model for Few-Shot Learning》 (DeepMind)](https://arxiv.org/abs/2204.14198)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《PaLM: Scaling Language Modeling with Pathways》 (Google)](https://arxiv.org/abs/2204.02311)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《PaLM-E: An Embodied Multimodal Language Model》 (Google)](https://arxiv.org/abs/2303.03378)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《GPT-4 Technical Report 》 (OPEN AI)](https://arxiv.org/abs/2303.08774)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《LLaMA: Open and Efficient Foundation Language Models》 (Meta)](https://arxiv.org/abs/2302.13971)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model）  |[《LLAVA: Visual Instruction Tuning》 (Microsoft, UWM)](https://arxiv.org/abs/2304.08485)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model --- Medical）  |[《Med-PALM : Large Language Models Encode Clinical Knowledge》 (Google)](https://arxiv.org/abs/2212.13138)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model --- Medical）  |[《BioMedCLIP: LARGE-SCALE DOMAIN-SPECIFIC PRETRAINING FOR BIOMEDICAL VISION-LANGUAGE PROCESSING》 (Microsoft)](https://arxiv.org/pdf/2303.00915.pdf)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model --- Medical）  |[《LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day 》 (Microsoft)](https://arxiv.org/pdf/2306.00890.pdf)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model --- Medical）  |[《Med-Flamingo: MED-FLAMINGO: A MULTIMODAL MEDICAL FEWSHOT LEARNER 》 (Stanford)](https://arxiv.org/pdf/2307.15189.pdf)
|2023.10.13 | Yucheng Tang  <br> （Vision Language Foundation Model --- Medical）  |[《Towards Generalist Foundation Model for Radiology 》 (Shanghai AI Lab)](https://arxiv.org/pdf/2308.02463.pdf)
|2023.10.6 | Dr. Huo  <br> （Vision language model）  |[《CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection》 （arxiv）](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.pdf)
|2023.10.6 | Dr. Huo  <br> （Fast data curation）  |[《Annotating 8,000 Abdominal CT Volumes for Multi-Organ Segmentation in Three Weeks》 （ICCV 2023）](https://arxiv.org/pdf/2305.09666.pdf)
|2023.10.6 | Dr. Huo  <br> （Tranformer backbone）  |[《UNesT: Local Spatial Representation Learning with Hierarchical Transformer for Efficient Medical Segmentation》 （MeDIA 2023）](https://browse.arxiv.org/pdf/2209.14378.pdf)
|2023.9.22 | Tianyuan Yao  <br> （Vision language model）  |[《BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning》 （AAAI 2023）](https://arxiv.org/pdf/2206.08657.pdf)
|2023.9.22 | Tianyuan Yao  <br> （Vision language model）  |[《PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents》 （MICCAI 2023）](https://arxiv.org/pdf/2303.07240.pdf)
|2023.9.22 | Tianyuan Yao  <br> （Representation disentanglement + segmentation）  |[《Directional Connectivity-based Segmentation of Medical Images》 （CVPR 2023）](https://arxiv.org/ftp/arxiv/papers/2304/2304.00145.pdf)
|2023.9.22 | Tianyuan Yao  <br> （Semi-supervised Segmentation）  |[《Orthogonal Annotation Benefits Barely-supervised Medical Image Segmentation》 （CVPR 2023）](https://arxiv.org/pdf/2303.13090.pdf)
|2023.9.15 | Ruining Deng  <br> （Prompt-based Segmentation）  |[《Incrementer: Transformer for Class-Incremental Semantic Segmentation with Knowledge Distillation Focusing on Old Class》 （CVPR2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Shang_Incrementer_Transformer_for_Class-Incremental_Semantic_Segmentation_With_Knowledge_Distillation_Focusing_CVPR_2023_paper.pdf)
|2023.9.15 | Ruining Deng  <br> （Prompt-based Segmentation）  |[《SegPrompt: Boosting Open-world Segmentation via Category-level Prompt Learning》 （ICCV）](https://arxiv.org/pdf/2308.06531.pdf)
|2023.9.15 | Ruining Deng  <br> （Prompt-based Segmentation）  |[《ProSFDA: Prompt Learning based Source-free Domain Adaptation for Medical Image Segmentation》 （ArXiv）](https://arxiv.org/abs/2211.11514)
|2023.9.08|Dr. Huo     <br>  （Text-to-image Segmentation）  |[《Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models》 （ArXiv）](https://arxiv.org/pdf/2303.04803.pdf)
|2023.9.08|Dr. Huo     <br>  （Fundation Models）  |[《DINOv2 from Meta AI – Finally a Foundational Model in Computer Vision》 （Web Site）](https://aipapersacademy.com/dinov2-from-meta-ai-finally-a-foundational-model-in-computer-vision/) [(ArXiv)](https://arxiv.org/abs/2304.07193)
|2023.9.08|Dr. Huo     <br>  （Fundation Models）  |[《SAM-Med2D》 （ArXiv）](https://arxiv.org/pdf/2308.16184.pdf)
|2023.8.25|Quan Liu     <br>  （Self-supervised Learning）  |[《EMP-SSL: Towards Self-Supervised Learning in One Training Epoch》 （CVPR 2023）](https://arxiv.org/abs/2304.03977)
|2023.8.25|Quan Liu     <br>  （Vision language model + zero-shot learning）  |[《Visual Language Pretrained Multiple Instance Zero-Shot Transfer for Histopathology Images》 （CVPR 2023）](https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_Visual_Language_Pretrained_Multiple_Instance_Zero-Shot_Transfer_for_Histopathology_Images_CVPR_2023_paper.pdf)
|2023.8.25|Quan Liu     <br>  （Image perturbation）  |[《Revisiting Weak-to-Strong Consistency in Semi-Supervised Semantic Segmentation》 （CVPR 2023）](https://arxiv.org/pdf/2208.09910.pdf)





## Pool of great papers from the team (Senior folks can drop papers here as potential papers to review)
1. Ye, Shuquan, et al. "Improving Commonsense in Vision-Language Models via Knowledge Graph Riddles." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023. [from Yuankai Huo]

1. Xie, Ronald, et al. "MAESTER: Masked Autoencoder Guided Segmentation at Pixel Resolution for Accurate, Self-Supervised Subcellular Structure Recognition." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023. [from Yuankai Huo]

1. Huang, Zhi, et al. "A visual–language foundation model for pathology image analysis using medical Twitter." Nature Medicine (2023): 1-10. [from Yuankai Huo]
